---
title: "Analyzing Economic Shocks"
author: "Ziling Zhang, Leah Hunt, and Jiahui Cheng"
subtitle: "Stat 470W"
date: "11/17/2020"
output:
  pdf_document:
    toc: yes
    toc_depth: '2'
header-includes: 
- \usepackage{float}    
---
\newpage
```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = FALSE,message=FALSE,warning = FALSE, fig.pos = "H", out.extra = "")
library(lubridate)
library(ggplot2)
library("tidyverse")
library("cluster")
library("factoextra")
library(stats)
library(tidyr)
data <- read.table("economicData.txt", header = TRUE)
data$inflation <- c(NA, (data$cpi[2:length(data$cpi)] - data$cpi[1:length(data$cpi)-1])/
                  data$cpi[1:length(data$cpi)-1])
data <- data[,c("DATE", "DOW_Close", "unemployment", "oil", "gold",
                "federal_funds_rate", "consumer_confidence", "inflation")]
data <- na.omit(data)
datad <- read.table("economicDataDaily.txt", header = TRUE)
```

# Abstract
An economic shock is an event that causes a, generally sudden, change in the economy. Examples of shocks include the introduction of COVID-19, the deadly disease that has been spreading globally throughout 2020. This analysis seeks to examine the structure of the economy in such shock periods in comparison to non-shock periods. We will first identify shock periods using data then apply regression and time series modelling to analyze the differences in economic structure between periods identified as shocks and those not identified.


# Introduction

## Background and Motivation

The COVID-19 pandemic, which originated in Wuhan, China at the end of 2019 and has since spread globally, has largely impacted society on both social and economic levels. An analysis by Zekra identifies the largest economic impacts of the virus to be medical treatment costs, extensive use of limited medical resources that takes away from other health issues, economic disruption from social distancing and quarantining, decreases in tourism, and impacts on foreign investment. (Zekra) In this sense, the COVID-19 pandemic is but one example of an economic shock, which we will consider a period of rapid change incited by a particular event, which often causes rapid change in the economy.

When considering these shock periods, clearly there will be differences in some aspects of their impacts. For example, the shock caused by the 9/11 terrorist attacks would not feature major effects to the healthcare system nationally or restrictions imposed by social distancing. As Zeshan explores through simulation in relation to the COVID-19 shock, we can even see different industries be hit in different ways and with different magnitudes in particular shocks, thus adding a further level of complexity. (Zeshan) We would, however, still expect some similarities. For instance, in our prior example, both the pandemic and the 9/11 terrorist attacks would feature a decrease general outlook, which we will quantify through consumer confidence, and impacted the airline industry. 

For this analysis, we will take a larger scale approach to exploring the effects of shocks on the economy. We will attempt to model economic structure as a whole using common metrics of economic performance as opposed to considering particular impacted industries like the approach from Zeshan. In particular, we will use regression and time series techniques to develop models representing the economy's structure in order to identify and analyze shock periods, in particular comparing relative to the effects of the COVID-19 shock.

## Assumptions on Economic Structure

In order to complete our analysis, we will be making a few assumptions on the economic structure as a whole. First, we will consider the DOW Jones Composite Average to be a reasonable metric for overall economic performance and thus will use this as our response variable in modelling. We consider the DOW Jones Composite Average a reasonable indicator of economic performance because it includes data from 65 major companies including ones from each of the major DOW sectors: industrial, utility, and transportation, thus giving a somewhat broad look at the economy overall. 

We will also assume that economic trends as a whole, in our case being modelled by the DOW, can be split into three types: a general trend that can be modelled as a linear function, periodic fluctuations that can be modelled through time series, and shocks, which will show up as larger amounts of variation remaining after accounting for the first two, noting that we will still have to distinguish between random error and shocks at this stage. We will assume that shocks have a large enough impact to be distinguished from the random error in the data. An illustration of this structure is shown in the below figure.

```{r tot, fig.cap="This figure illustrates the economic trends over time as described by our model. The black line represents the general trend with the red curve showing the natural fluctuations added to this general trend. The blue segments show two examples of shocks. Note that the shock around 1.4 is a negative shock and the one around 3.4 is a positive shock. The purple curve shows the sum of all of these components plus a small amount of noise, i.e. random error. Note that the units of the axis in this plot are arbitrary and that this plot was artificially generated with the sole intention of explaining the model.", fig.height=3}
set.seed(470)
curve(x + jitter(.5*sin(4*x), amount = .1) + (x < 3.45 & x > 3.3)*.5 + (x < 1.45 & x > 1.3)*-.5, 
      col = "purple", xlim = c(0,4),xlab = "Time", ylab = "Economic Trend", 
      main = "Economic Trends Over Time")
curve(x + .5*sin(4*x) + (x < 3.45 & x > 3.3)*.5 + (x < 1.45 & x > 1.3)*-.5, col = "blue", add = TRUE)
curve(1*x, add = TRUE)
curve(x + .5*sin(4*x), add = TRUE, col = "red")
```

More formally, we can describe this structure as treating the economic structure as a three level model.


The first level is the general trend, which is represented by a linear model on the DOW:
\[
Y_{ijk} = \beta_0 + \beta_1t + a_{ij} + \epsilon_{ijk} 
\]
where $\epsilon_{ijk}$ ~ $N(0, \sigma^2)$.


The second level handles the natural fluctuations using a time series model:

\[
a_{ij} = \theta_1a_{ij-1} + u_{ij} + w_i
\]

where $u_{ij}$ ~ $N(0, \sigma_u^2)$.


The third level then represents the shocks, which for the sake of the model will be assumed to all have the same magnitude, even though this is a rather strong simplification of reality that will be accounted for in the error terms in our model:

\[
w_i = w_0 + \beta_2v_i + k_i
\]

where $k_{i}$ ~ $N(0, \sigma_k^2)$ and $v_i$ is an indicator variable representing whether a period is a shock period.

## Data Description

For this analysis, we will be using data collected primarily through Federal Reserve Economic Data (FRED) and yahoo finance which will cover a range of common economic indicators and stock prices. The first set of variables creates our monthly dataset, i.e. data that is reported on a monthly basis, and consists of the unemployment rate, consumer confidence index, DOW Jones Composite (taken on the first of the month), oil price, federal funds rate (taken on the first of the month), and the inflation rate.
We also consider a daily data set, i.e. data reported for each day, which consists of the DOW Jones Composite, gold price, S&P 500, New York Stock Exchange, and 10 year bond rates. A more detailed explanation of these variables is in Appendix A.

## Research Questions

**Question 1:** How do shock periods and non-shock periods differ in economic structure?

**Question 2:** What are the differences and similarities for different shocks, in particular comparing COVID-19 to other shocks such as the Great Recession?

## Statistical Research Questions

**Question 1:** How does the structure of the economy, as defined by the effectiveness of models used to predict the DOW, differ for shock periods? In particular, do shock periods have higher magnitude residuals than non-shock periods? 

**Question 2:** Are there significant differences between shocks in their ability to be fit to a model of economic structure and in the magnitude and nature of their effects, as evidenced by their residuals in the fitted economic models? 



# Exploratory Data Analysis

The main variable that we will consider as a response is the DOW, and as such, we want to get a better understanding of the DOW data. Looking at the raw DOW data, shown in the leftmost plot of Figure 1, we see that the shape is not linear, rather resembling a polynomial or exponential shape. In order to apply our theory of a linear general trend to the data, we will want to apply a transformation to the data; the log transform shown in the center plot of Figure 1 creates the more linear trend that we are aiming for. Note that while the trend may appear mildly curved, much of this slight curved appearance comes from the rapid growth in the 1990's that was caused by the introduction of the Internet. Thus, this trend still reasonably falls under the assumptions of the model, though it does indicate that the introduction of the Internet may constitute an unindentified shock in our model.

```{r eda1, fig.cap="The above figure shows different methods of showing the DOW using the monthly data. Notice that the center plot is more linear than the leftmost, which justifies the log transform. For analysis, we will also consider the changes in DOW, represented in the rightmost plot.", fig.height=3}
par(mfrow =c(1,3))
plot(ymd(data$DATE), data$DOW_Close, ylab = "DOW", 
     xlab = "Date", main = "DOW over Time")
plot(ymd(data$DATE), log(data$DOW_Close), ylab = "log DOW", 
     xlab = "Date", main = "Logarithm of \nDOW over Time")
DowDiff <- log(data$DOW_Close)[2:length(data$DOW_Close)] -
  log(data$DOW_Close)[1:length(data$DOW_Close)-1]
plot(ymd(data$DATE)[2:length(data$DOW_Close)], DowDiff, ylab = "log DOW Differences",
     xlab = "Date", 
     main = "Logarithm of DOW \nDifferences over Time")
```

For our analysis, we will also want to consider the changes in the DOW, primarily for the sake of meeting the stationarity assumption. We see in the rightmost plot of Figure 1 that these values appear randomly around 0, meaning that we may not expect to find a significant trend over time. This is consistent with economic theory, which claims that we will not be able to predict these changes well. Keep in mind that even as we attempt to do so throughout this work, we will only be aiming to model the general structure with no predictive power. We do, however, see several points with larger changes, which we will analyze as we attempt to identify outliers.


Figure 2 considers similar ideas for the daily DOW data. While the first two plots look very similar, the third really emphasizes the main difference between using monthly and daily data. The daily data has much more noise, which is partially a product of having much more data to work with. In the rightmost plot, we again see a lot of seemingly random variation around 0 but with a some periods with seemingly higher variation. 

```{r eda2, fig.cap="The above figure shows different methods of showing the DOW using the daily data. Notice that the center plot is more linear than the leftmost, which justifies the log transform. For analysis, we will also consider the changes in DOW, represented in the rightmost plot.", fig.height=3}
par(mfrow =c(1,3))
plot(ymd(datad$DATE), datad$DOW, ylab = "DOW", xlab = "Date", main = "DOW over Time")
plot(ymd(datad$DATE), log(datad$DOW), ylab = "log DOW", xlab = "Date", 
     main = "Logarithm of \nDOW over Time")
DowDiffd <- log(datad$DOW)[2:length(datad$DOW)] - log(datad$DOW)[1:length(datad$DOW)-1]
plot(ymd(datad$DATE)[2:length(datad$DOW)], DowDiffd, ylab = "log DOW diff", 
     xlab = "Date", main = "Logarithm of DOW \nDifferences over Time")
```


Of course, we also want to consider the explanatory variables and their relationship to the DOW. Further plots and analysis considering these variables can be found in Appendix B.


# Identifying and Defining Shock Periods

We define shock periods as periods of large change, excluding change from the general trend, in the DOW Jones composite score, using this metric as our indicator for the economy as a whole. We will consider two potential periods for shock identification: by month and by day. Each of these analyses will also use the logarithm of the DOW instead of the DOW itself in order to have a general trend closer to linear, as discussed in the exploratory analysis. For the remainder of this section, any mention of the DOW score can be assumed to be referring to the logarithm of the DOW unless otherwise stated.

## Shock Identification by Month

Our first step in identifying shock periods is to exclude the natural trend using linear regression to model the DOW with time as the only predictor. The results of this step are shown in the below figure. 

```{r regMonthly, fig.cap = "This figure shows the results of the linear fit to remove the general trend. While this fit would generally not be considered a good fit to the data, its purpose is only to remove a generic trend, which it effectively does.", fig.height=3}
reg <- lm(log(DOW_Close)~
            poly(time(DATE),degree = 1,raw = T),data=data)
par(mfrow =c(1,2))
plot(ymd(data$DATE), log(data$DOW_Close), xlab = "Date", ylab = "log DOW", 
     main = "Linear Trend of\n log DOW over Time")
curve(6.131019  + 0.006492 * 12 * (year(as.Date(x, origin = "1981-01-01"))-1992) + 
        0.006492 *month(as.Date(x, origin = "1981-01-01")-1), 
      col = "red", add = TRUE) # I have no idea why this line of code works...my guess is that you have to scale back by 12 to accommodate the multiplication but IDK why...
plot(ymd(data$DATE), reg$residuals,ylab = "residuals", xlab = "Date", 
     main = "Residuals from\nLinear Trend")
```

Note that in the process of using a linear model and even fitting our line through linear regression, we are not intending to model our data in this step, but rather model, and then remove, only one small portion of the trend in the data. 

Now that we have removed the general trend, we must consider the changes in the DOW, i.e. consider the changes between the residuals of our linear model. We will use a time series model in order to understand the trend in these changes. We will consider outliers, defined as having a residual of more than three standard deviations, where the standard deviation is calculated from the residuals themselves, from 0. A visualization of the residuals of the time series model and the cutoffs are shown below. 

```{r, fig.cap = "This figure shows the model residuals. The red lines represent three standard deviations from 0. The seven points below the lower red line are the seven identified shocks.", fig.height=3}
# Difference between residuals
res_temp <- reg$residuals[2:length(reg$residuals)] - reg$residuals[1:length(reg$residuals)-1]
mod1 <- arima(res_temp,order = c(1,0,0))
outliersmonsig <- which(abs(mod1$residuals) > 3*sqrt(var(mod1$residuals)))
plot(ymd(data$DATE)[2:length(reg$residuals)], res_temp, ylab = "Change in residual", xlab = "Date")
abline(h = -3*sqrt(var(mod1$residuals)), col = "red") # 3 standard deviations below
abline(h = 3*sqrt(var(mod1$residuals)), col = "red") # 3 standard deviations above
```

We see that the analysis identifies seven points as shocks. In order to verify these points, we can trace them back to actual events. The dates of these seven shocks and their associated events are shown below. 

```{r}
A <- c("October 1987", "Black Monday stock market crash on October 19, 1987")
B <- c("August 1990", "Beginning of the Gulf War (officially started August 2, 1990)")
C <- c("August 1998", "Russian financial crisis")
D <- c("September 2001", "9/11 terrorist attack")
E <- c("October 2008", "Great Recession; TARP relief bill signed")
G <- c("February 2009" , "Great Recession; congress passes large stimulus package")
H <- c("March 2020", "First major reactions to COVID-19 pandemic begin in the US")
varExplanations <- matrix(c(A, B,C,D,E,G,H), ncol = 2, byrow = TRUE)
varExplanations <- as.data.frame(varExplanations)
#varExplanations
colnames(varExplanations) <- c("Time", "Event")
knitr::kable(varExplanations, 
             caption = "Associated events for each identified shock period",
             align = c('c', rep('l', 2))) %>%
kableExtra::kable_styling(bootstrap_options = c("striped", "condensed"),
                          font_size = 9, latex_options = "HOLD_position")
```

## Shock Identification by Day

In order to consider the shocks by daily data, we will use the same process as we used for the monthly data on its daily counterpart. The major difference will be the magnitude of data and the level of volatility in the data as daily data features much more noise than the monthly data. 

Once again, we start by removing the general linear trend, as seen in the below figure.

```{r regdaily, fig.cap = "This figure shows the results of the linear fit to remove the general trend. While this fit would generally not be considered a good fit to the data, its purpose is only to remove a generic trend, which it effectively does.", fig.height=3}
regd <- lm(log(DOW)~
            poly(time(DATE),degree = 1,raw = T),data=datad)
par(mfrow =c(1,2))
plot(log(datad$DOW))
abline(regd, col = "red")
plot(ymd(datad$DATE), regd$residuals,ylab = "residuals", xlab = "Date")
```

Then, we consider the changes in these residuals between days and run a time series model on these changes, again looking for residuals that are further than three standard deviations from 0. 

```{r, fig.cap = "This figure shows the model residuals. The red lines represent three standard deviations from 0. The shocks are the points that do not fall between the red lines. The blue lines show the periods that were considered shocks in the monthly analysis for reference.", fig.height=3}
# Difference between residuals
res_tempd <- regd$residuals[2:length(regd$residuals)] - regd$residuals[1:length(regd$residuals)-1]
mod1d <- arima(res_tempd,order = c(1,0,0))
#outliers <- forecast::tsoutliers(mod1$residuals)$index
#data$DATE[outliers+1]
#data$DATE[which(abs(mod1$residuals)>3*sqrt(var(mod1$residuals)))]
outliersmonsigd <- which(abs(mod1d$residuals) > 3*sqrt(var(mod1d$residuals)))
plot(ymd(datad$DATE)[2:length(regd$residuals)], res_tempd, ylab = "Change in residual", xlab = "Date")
abline(h = -3*sqrt(var(mod1d$residuals)), col = "red") # 3 standard deviations below
abline(h = 3*sqrt(var(mod1d$residuals)), col = "red") # 3 standard deviations above
abline(v = ymd(data$DATE[outliersmonsig]), col = "blue") #IDK if we should keep these
abline(v = ymd(data$DATE[outliersmonsig+1]), col = "blue") #Also, check if this is doing what it is supposed to...
```

Compared to the monthly case, we see many more shock points. We see, however, that the points that we had previously identified as shocks do appear to some degree using this method as well with all seven cases having at least one shock day within the month and some cases like Black Monday showing up as distinct days.  

# Modelling

## Approach

After identifying 7 shocks on both statistical and economic perspective, we want to examine these 7 shocks, comparing them with other regular periods by modelling the economic structure. As stated from the assumptions above, we assume economic structure is a linear combination of general trend, shocks, and fluctuations. Thus, our statistical approach to model economic structure is to use a linear model by considering time series effects, which are quantified by using cross correlation and then including correlated time periods. 

After modelling the economic structure, we tend to compare shocks and non-shock periods by looking at their residuals. 

## Analysis on Monthly Data

For the monthly data, we choose the response variable as *Dow_Close* value. We also choose 6 monthly reported economic predictors to measure the strucuture. Our goal is to examine how stock market (economy) will respond to changes in macrovarables. To normalize the data, we take log of the difference of all our variables except for inflation, which is equal to take the percent change of our values. More importantly, such transformation can satify our assumption of stationarity on response variable. 

```{r}
# Variable table INCOMPLETE
# variable<-data.frame(
#   No = c(1,2,3,4,5,6,7,8,9),
#   Variable=c("Dow_Close","unemployment","oil","gold","federal funds rate","consumer confidence index","inflation rate"),
#   Description = 
#     c(""), 
#   Units = c(''))
# knitr::kable(variable,
#              caption = "Variable Attributes",
#              align = c('c', rep('l', 7)),format="latex") %>%
# kableExtra::kable_styling(bootstrap_options = c("striped", "condensed"),
#                           font_size = 7, latex_options = "HOLD_position")
```

Firstly, check the figure of *Dow_Close* after transformation. 
```{r}
# transform all variables
Dowm=as.ts(log(data$DOW_Close[2:474])-log(data$DOW_Close[1:473])) 
unemploymentm=na.omit(as.ts(log(data$unemployment[2:474]) - log(data$unemployment[1:473])))
oilm=na.omit(as.ts(log(data$oil[2:474]) - log(data$oil[1:473])))
goldm=na.omit(as.ts(log(data$gold[2:474]) - log(data$gold[1:473])))
ffrm=na.omit(as.ts(log(data$federal_funds_rate[2:474]) - log(data$federal_funds_rate[1:473])))
ccim=na.omit(as.ts(log(data$consumer_confidence[2:474]) - log(data$consumer_confidence[1:473])))

plot(ymd(data$DATE)[1:473],Dowm,xlab="Date",ylab="percent change of Dow_Close")
```
Then we will take the cross correlation between *Dow_Close* and 6 predictors. The goal of this step is to examine the effects of time series. All variables are not statistically independent since they all depend on time. One important feature for economic predictor is that current value might depend on previous values. Thus, before we examine the relationship among predictors in economic structure, we also want to consider the effects of the past. 

Using cross correlation figures, we can easily check past significant lags that will influence current value of predictors. So that, we can include those lags into consideration. 

From the cross correlation figures, we notice unemployment rate at lag -1 and -2, oil at lag -1, gold price at lag -1, inflation rate at -2,-3, federal funds rate at lag -2, and consumer confidence index at current lag and -1 are significant with current *Dow_Close* value. Thus, we need to consider them into the linear model. 

```{r, fig.cap = "This figure shows cross correlation between Dow and 6 predictors.The x-axis is the lag, while before 0 represents past and after future. Future analysis is meaningless here since we will not do prediction. Lag that is higher than blue line means it is significant", fig.height=3}
# cross correlation 
# par(mfrow=c(3,3))
# 
# ccf(Dowm,unemploymentm)
# ccf(Dowm,oilm)
# ccf(Dowm,goldm)
# ccf(Dowm,data$inflation)
# ccf(Dowm,ffrm)
# ccf(Dowm,ccim)
```

```{r}
# linear model 

alldata=ts.intersect(Dowm,un1 =stats::lag(unemploymentm,-1),un2=stats::lag(unemploymentm,-2),
                     oil1=stats::lag(oilm,-1), 
                     gold=stats::lag(goldm,-1), 
                     inf1=stats::lag(data$inflation,-2), inf2=stats::lag(data$inflation,-3),
                     ffr2=stats::lag(ffrm,-2),
                     cci=stats::lag(ccim,0),cci1=stats::lag(ccim,-1))

modelccf=lm(Dowm~un1+un2+oil1+gold+inf1+inf2+ffr2+cci+cci1,data=alldata)
summary(modelccf)

plot(resid(modelccf))
```

INCOMPLETE: approach, plug in the shocks identified before and check how do their residuals look like


## Analysis on Daily Data

For the monthly data, we still choose the response variable as *Dow_Close* value. We also choose 4 daily reported economic predictors to measure the strucuture. Our goal is to examine how stock market (economy) will respond to changes in macrovarables. To normalize the data, we take log of the difference of all our variables except for inflation, which is equal to take the percent change of our values. More importantly, such transformation can satify our assumption of stationarity on response variable. 

```{r}
# Variable table INCOMPLETE
variable<-data.frame(
  No = c(1,2,3,4,5),
  Variable=c("Dow_Close","DGS10","SP500","gold","NYSE"),
  Description = 
    c(""), 
  Units = c(''))
knitr::kable(variable,
             caption = "Variable Attributes",
             align = c('c', rep('l', 7)),format="latex") %>%
kableExtra::kable_styling(bootstrap_options = c("striped", "condensed"),
                          font_size = 7, latex_options = "HOLD_position")
```


```{r}

datadd=na.omit(datad)

```



# Discussion

# Limitations and Future Study


# Works Cited

Board of Governors of the Federal Reserve System (US), 10-Year Treasury Constant Maturity Rate [DGS10], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/DGS10, November 30, 2020.

Board of Governors of the Federal Reserve System (US), Effective Federal Funds Rate [DFF], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/DFF, September 6, 2020.

^DJA historical prices, DOW Jones Composite Average common stock. (n.d.). Retrieved September 6, 2020 from https://finance.yahoo.com/quote/%5EDJA/history?p=%5EDJA, September 6, 2020

Federal Reserve Bank of St. Louis, Spot Crude Oil Price: West Texas Intermediate (WTI) [WTISPLC], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/WTISPLC, September 6, 2020.

^GSPC historical prices, S&P 500 common stock. (n.d.). Retrieved September 6, 2020 from https://finance.yahoo.com/quote/%5EGSPC?p=^GSPC&.tsrc=fin-srch, September 6, 2020

ICE Benchmark Administration Limited (IBA), Gold Fixing Price 10:30 A.M. (London time) in London Bullion Market, based in U.S. Dollars [GOLDAMGBD228NLBM], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/GOLDAMGBD228NLBM, September 6, 2020.

^NYA historical prices, NYSE Composite (DJ) common stock. (n.d.). Retrieved September 6, 2020 from https://finance.yahoo.com/quote/%5ENYA?p=^NYA&.tsrc=fin-srch, September 6, 2020

Surveys of Consumers, University of Michigan, University of Michigan: Consumer Sentiment [UMCSENT], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/UMCSENT, September 6, 2020.

U.S. Bureau of Labor Statistics, Consumer Price Index for All Urban Consumers: All Items in U.S. City Average [CPIAUCSL], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/CPIAUCSL, September 6, 2020.

U.S. Bureau of Labor Statistics, Unemployment Rate [UNRATE], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/UNRATE, September 6, 2020.

Zekra, L. (2020). COVID-19 Pandemic and Global Economic Impact. *Ovidius University Annals, Economic Sciences Series*, 0(1), 237-244. Retrieved September 22, 2020, from https://ideas.repec.org/a/ovi/oviste/vxxy2020i1p237-244.html This source breaks down the economic impacts of COVID-19. It discusses impacts from the disease itself as well as from measures taken to combat the disease. It also discusses individual industries, both those hurt and those helped by the pandemic.


Zeshan, M. (2020). Double-hit scenario of Covid-19 and global value chains. *Environment, Development and Sustainability*. doi:10.1007/s10668-020-00982-w This article considers which sectors of the economy were most hit by COVID-19 and found that all sectors had at least mild impact with some larger than others.

# Appendix A: Full Variable Description
```{r}
date <- c("DATE", "", "Date on which observations were taken; reported as the first of the month")
dow <- c("DOW", "Dollars", 
         "Gives the value of the DOW Jones Composite as of closing on the first \nof the month")
unemployment <- c("unemployment", "", 
                  "US unemployment rate (unemployed/total people)")
oil <- c("oil", "dollars/barrel",
         "Price of oil; based out of West Texas")
gold <- c("gold", "dollers/ounce",
          "Price of gold as of the first of the month; based on London Bullion Market")
cpi <- c("cpi", "relative to 1982-1984" , 
         "Consumer price index; amount that 1 dollar is worth in 1982-1984 dollars")
ffr <- c("ffr", "", 
         "Federal Funds Rate set by the Federal Reserve")
cc <- c("consumer_confidence", "",
"Consumer confidence using the University of Michigan Consumer Sentiment 
        index with 1966 as the base year")
varExplanations <- matrix(c(date, dow, unemployment, oil, gold, cpi, ffr, cc), 
                          ncol = 3, byrow = TRUE)
varExplanations <- as.data.frame(varExplanations)
colnames(varExplanations) <- c("Variable Name", "Unit", "Description")
knitr::kable(varExplanations, 
             caption = "Full description of all monthly variables",
             align = c('c', rep('l', 2))) %>%
kableExtra::kable_styling(bootstrap_options = c("striped", "condensed"),
                          font_size = 9, latex_options = "HOLD_position")%>%
  kableExtra::column_spec(3, width = "30em")
```

```{r}
date <- c("DATE", "", "Date on which observations were taken; reported as the first of the month")
dow <- c("DOW", "dollars", "Value of the DOW Jones Composite as of closing on the particular day")
nyse <- c("nyse", "dollars", 
          "Value for the New York Stock Exchange on the particular day as of closing")
bond <- c("bond10", "dollars", "10 year US bond prices")
sp <- c("sp", "dollars", "Value of the S&P 500 Index")
gold <- c("gold", "dollers/ounce", "Price of gold; based on London Bullion Market")
varExplanations <- matrix(c(date, dow, nyse, bond, sp, gold), ncol = 3, byrow = TRUE)
varExplanations <- as.data.frame(varExplanations)
colnames(varExplanations) <- c("Variable Name", "Unit", "Description")
knitr::kable(varExplanations, 
             caption = "Full description of all daily variables",
             align = c('c', rep('l', 2))) %>%
kableExtra::kable_styling(bootstrap_options = c("striped", "condensed"),
                          font_size = 9, latex_options = "HOLD_position")
```

May want to write in more on how the DOW, S&P, nyse, etc. are calculated and what each of these are relevant for


# Appendix B: Additional Plots and Exploratory Analysis

## Monthly Data
```{r appb1, fig.cap="These plots show the monthly exploratory variables over time with the DOW also shown for reference. The blue vertical lines show the shock periods identified by the analysis. Notice that in the explanatory variables, the peaks and periods of larger change appear correlated with the movements of the DOW. Likewise, the shocks often appear in times where the explanatory variables are experiencing change."}
par(mfrow =c(2,3))
for(i in c(2:6)){
  plot(ymd(data$DATE), data[,i], 
       ylab = colnames(data)[i], xlab = 'Date', main = colnames(data)[i])
  abline(v = ymd(data$DATE[outliersmonsig]), col = "blue") 
}
```

```{r appb2, fig.cap = "These plots show the DOW plotted by the explanatory variables over time. For the unemployment rate, we can see a negative relationship with the DOW, even as the magnitude of the DOW increases overtime. The remaining variables seem to have a stronger relationship with time, though in cases like the federal funds rate this can lead to apparent relationships with the DOW, in the case of the federal funds rate appearing to have a negative relationship and in the case of gold prices appearing as a positive relationship."}
dataLong <- pivot_longer(data, cols = 3:6, names_to = "Var", values_to = "Val")
ggplot(aes(x = Val, y = (DOW_Close), color = ymd(DATE)), data = dataLong) +
     geom_point() +
  facet_wrap(facets = vars(Var),scales="free") + 
  labs(color = "Date", y = "log DOW", x = "Explanatory Variables", 
       title = "DOW vs. Explanatory Variables over Time")
```

```{r appb3, fig.cap="These plots show the monthly log changes in the explanatory variables with the DOW as reference. The blue lines show the shock periods. Notice how some variables, such as oil price, have large changes near several of the shock periods while others, such as gold prices, do not have any corresponding large residual points to correspond with the shocks. Also keep in mind that log differences act similarly to percentage change, and as such the seemingly large changes in the federal funds rate in the 2010s comes from the very small magnitude of the federal funds rate in that period combined with the fact that it is generally changed in increments of .25%. "}
dataDiffs <- data
for(col in 2:ncol(data)){
  for(row in 2:nrow(data)){
    dataDiffs[row, col] <- log(data[row, col]) - log(data[row-1, col])
  }
}
dataDiffs <- dataDiffs[2:nrow(dataDiffs),]
par(mfrow =c(2,3))
for(i in c(2:6)){
  plot(ymd(dataDiffs$DATE), dataDiffs[,i], ylab = colnames(dataDiffs)[i], 
       xlab = 'Date', main = colnames(data)[i])
  abline(v = ymd(dataDiffs$DATE[outliersmonsig]), col = "blue") 
}
```

From the monthly variables, we can see several patterns emerging between the different shock periods. For instance, the Great Recession and COVID-19 related shocks tend to have similar changes among the variables with larger magnitudes of changes relative to other variables. Exceptions to this trend include unemployment, which had a more gradual increase during the Great Recession compared to COVID-19 and gold prices, which were more of a gradual increase in COVID-19 relative to other shocks like the Great Recession shocks and the start of the Gulf War.

## Daily Data

```{r appb4, fig.cap="These plots show the daily exploratory variables over time with the DOW also shown for reference. The blue vertical lines show the shock periods identified by the analysis. Notice that in the explanatory variables, the peaks and periods of larger change appear correlated with the movements of the DOW. Likewise, the shocks often appear in times where the explanatory variables are experiencing change."}
par(mfrow =c(2,3))
for(i in c(2:6)){
  plot(ymd(datad$DATE), datad[,i], ylab = colnames(datad)[i], xlab = 'Date', 
       main = colnames(datad)[i])
  abline(v = ymd(data$DATE[outliersmonsig]), col = "blue")
abline(v = ymd(data$DATE[outliersmonsig+1]), col = "blue") 
}
```




```{r appb5, fig.cap = "These plots show the DOW plotted by the daily explanatory variables over time. All of the variables seem to have a relationship with the DOW, though notably this could be equally stated as having a particular relationship with time. All but bond prices (DGS10) have a positive relationship with DOW and time, bond prices having a negative relationship."}
datad$DGS10 <- as.numeric(datad$DGS10)
datad$gold <- as.numeric(datad$gold)
dataLongd <- pivot_longer(datad, cols = 3:6, names_to = "Var", values_to = "Val")
ggplot(aes(x = Val, y = (DOW), color = ymd(DATE)), data = dataLongd) +
     geom_point() +
  facet_wrap(facets = vars(Var),scales="free") + 
  labs(color = "Date", y = "DOW", x = "Explanatory Variables", 
       title = "DOW vs. Explanatory Variables over Time")
```



```{r appb6, fig.cap="These plots show the daily log changes in the explanatory variables with the DOW as reference. Notice that each of the variables has increased variability around most if not all of the shock periods."}
dataDiffsd <- datad
for(col in 2:ncol(datad)){
  for(row in 2:nrow(datad)){
    dataDiffsd[row, col] <- log(datad[row, col]) - log(datad[row-1, col])
  }
}
dataDiffsd <- dataDiffsd[2:nrow(dataDiffsd),]
par(mfrow =c(2,3))
for(i in c(2:6)){
  plot(ymd(dataDiffsd$DATE), dataDiffsd[,i], ylab = colnames(dataDiffsd)[i], 
       xlab = 'Date', main = colnames(datad)[i])
  abline(v = ymd(dataDiffs$DATE[outliersmonsig]), col = "blue") 
}
```

The similarity between the COVID-19 shock and the Great Recession shocks is even more clear in the daily data. These two periods nearly across the board have the most volatility of any of the periods, with the exception of Black Monday in some instances and COVID-19 gold prices, which were less volatile. To some extent, the shocks are all recognizable in the predictor variables, though some cases are more subtle than others, for example with the bond prices where the Gulf War has only a very small impact.

# Appendix C: Assumption checks for modelling economic structure


# R Script
```{r codeAppendix, ref.label = knitr::all_labels(), echo = TRUE, eval = FALSE}
# Reprinted code chunks used previously for analysis
```
